import torch
import os
import sys
import numpy as np

sys.path.append(os.path.dirname(os.path.abspath(__file__)))
from env.game_env import äº¬é—¨å¥•ç¯å¢ƒ
from agent import DQNAgent


def train():
    env = äº¬é—¨å¥•ç¯å¢ƒ()
    agent = DQNAgent(env.çŠ¶æ€ç»´åº¦, env.åŠ¨ä½œæ•°é‡)

    EPISODES = 2000
    best_reward = -float('inf')
    recent_rewards = []

    print(f"ğŸš€ å¼€å§‹è®­ç»ƒ (ç»´åº¦:{env.çŠ¶æ€ç»´åº¦})...")

    for episode in range(EPISODES):
        state = env.reset()
        total_reward = 0
        done = False

        # å‰ 800 å±€å¼€å¯'è€å¸ˆå‚…æ¨¡å¼'ï¼šå¼ºåˆ¶åªé€‰åˆæ³•åŠ¨ä½œï¼Œè®©AIä½“éªŒèµ¢çš„æ„Ÿè§‰
        use_heuristic = (episode < 800)

        while not done:
            action = agent.choose_action(state, heuristic=use_heuristic)
            next_state, reward, done, _ = env.step(action)

            agent.store_transition(state, action, reward, next_state, done)
            agent.learn()

            state = next_state
            total_reward += reward

            if len(agent.memory) > 5000 and total_reward < -200: done = True  # æ—©åœ

        recent_rewards.append(total_reward)
        if len(recent_rewards) > 50: recent_rewards.pop(0)
        avg = np.mean(recent_rewards)

        if avg > best_reward and episode > 100:
            best_reward = avg
            torch.save(agent.policy_net.state_dict(), "best_model.pth")
            print(f"ğŸŒŸ æ–°é«˜åˆ†: {best_reward:.2f}")

        if episode % 10 == 0:
            agent.update_target_network()

        if (episode + 1) % 100 == 0:
            print(f"ğŸ“Š å›åˆ {episode + 1}: å¹³å‡åˆ† {avg:.2f} | Epsilon {agent.epsilon:.2f}")


if __name__ == "__main__":
    train()